/**
 * SERVICE: Voice Chat Service
 *
 * =====================================================
 * DECIS√ïES ARQUITETURAIS (DEFINITIVO)
 * =====================================================
 *
 * - N√ÉO usa base64 ‚ùå
 * - N√ÉO usa supabase.functions.invoke ‚ùå
 * - Usa fetch direto + FormData ‚úÖ
 * - Envia File bin√°rio real (multipart/form-data) ‚úÖ
 *
 * Motivo:
 * - Whisper exige File bin√°rio real
 * - Edge Functions aceitam multipart nativamente
 * - Menos convers√£o = menos bugs
 */

export interface VoiceChatResponse {
  transcript: string;
  response: string;
  success: boolean;
}

/**
 * URLs da Edge Function
 *
 * üëâ LOCAL (supabase start):
 * http://localhost:54321/functions/v1/voice-chat
 *
 * üëâ PRODU√á√ÉO:
 * https://SEU-PROJETO.supabase.co/functions/v1/voice-chat
 */
const VOICE_CHAT_FUNCTION_URL =
  import.meta.env.DEV
    ? 'http://localhost:54321/functions/v1/voice-chat'
    : 'https://SEU-PROJETO.supabase.co/functions/v1/voice-chat';

/**
 * Processa √°udio completo:
 * 1. Envia √°udio para Whisper
 * 2. Recebe transcri√ß√£o
 * 3. Recebe resposta da IA
 */
export async function processVoiceChat(
  audioBlob: Blob
): Promise<VoiceChatResponse> {
  console.log('[VoiceChatService] Audio debug:', {
    size: audioBlob?.size,
    type: audioBlob?.type,
  });

  if (!audioBlob || audioBlob.size === 0) {
    throw new Error('√Åudio inv√°lido ou vazio');
  }

  /**
   * IMPORTANTE:
   * Whisper exige File com filename v√°lido
   */
  const audioFile = new File(
    [audioBlob],
    'audio.webm',
    {
      type: audioBlob.type || 'audio/webm',
      lastModified: Date.now(),
    }
  );

  const formData = new FormData();
  formData.append('file', audioFile);

  const res = await fetch(VOICE_CHAT_FUNCTION_URL, {
    method: 'POST',
    body: formData,
    // ‚ö†Ô∏è N√ÉO definir headers manualmente
  });

  if (!res.ok) {
    const errorText = await res.text();
    console.error('[VoiceChatService] Backend error:', errorText);
    throw new Error(`Erro na API (${res.status})`);
  }

  const data = await res.json();

  if (!data?.transcript) {
    throw new Error('Transcri√ß√£o n√£o retornada pelo backend');
  }

  return {
    transcript: data.transcript,
    response: data.response ?? '',
    success: true,
  };
}

/**
 * Apenas transcri√ß√£o (sem resposta da IA)
 */
export async function transcribeAudio(
  audioBlob: Blob
): Promise<string> {
  if (!audioBlob || audioBlob.size === 0) {
    throw new Error('√Åudio inv√°lido');
  }

  const audioFile = new File(
    [audioBlob],
    'audio.webm',
    {
      type: audioBlob.type || 'audio/webm',
      lastModified: Date.now(),
    }
  );

  const formData = new FormData();
  formData.append('file', audioFile);
  formData.append('transcriptOnly', 'true');

  const res = await fetch(VOICE_CHAT_FUNCTION_URL, {
    method: 'POST',
    body: formData,
  });

  if (!res.ok) {
    const errorText = await res.text();
    throw new Error(`Erro na transcri√ß√£o (${res.status}): ${errorText}`);
  }

  const data = await res.json();

  if (!data?.transcript) {
    throw new Error('Transcri√ß√£o vazia');
  }

  return data.transcript;
}

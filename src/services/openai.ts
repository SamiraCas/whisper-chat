/**
 * SERVICE: Voice Chat Service
 *
 * =====================================================
 * DECIS√ïES ARQUITETURAIS (DEFINITIVO)
 * =====================================================
 *
 * - ‚ùå N√ÉO usa base64
 * - ‚ùå N√ÉO usa supabase.functions.invoke
 * - ‚úÖ Usa fetch direto + FormData
 * - ‚úÖ Envia File bin√°rio real (multipart/form-data)
 *
 * Motivo:
 * - Whisper exige File bin√°rio real
 * - Edge Functions aceitam multipart nativamente
 * - Menos convers√£o = menos bugs
 */

export interface VoiceChatResponse {
  transcript: string;
  response: string;
  success: boolean;
}

/**
 * URLs da Edge Function
 *
 * üëâ LOCAL (supabase start):
 * http://127.0.0.1:54321/functions/v1/voice-chat
 *
 * üëâ PRODU√á√ÉO:
 * https://SEU-PROJETO.supabase.co/functions/v1/voice-chat
 */
const VOICE_CHAT_FUNCTION_URL =
  import.meta.env.DEV
    ? 'http://127.0.0.1:54321/functions/v1/voice-chat'
    : 'https://SEU-PROJETO.supabase.co/functions/v1/voice-chat';

/**
 * Processa √°udio completo:
 * 1. Envia √°udio para Whisper
 * 2. Recebe transcri√ß√£o
 * 3. Recebe resposta da IA
 */
export async function processVoiceChat(
  audioBlob: Blob
): Promise<VoiceChatResponse> {
  if (!(audioBlob instanceof Blob)) {
    throw new Error('Objeto de √°udio inv√°lido');
  }

  if (audioBlob.size === 0) {
    throw new Error('√Åudio vazio');
  }

  console.log('[VoiceChatService] Audio debug:', {
    size: audioBlob.size,
    type: audioBlob.type,
  });

  /**
   * IMPORTANTE:
   * Whisper exige File real com filename v√°lido
   */
  const audioFile = new File(
    [audioBlob],
    'audio.webm',
    {
      type: audioBlob.type || 'audio/webm',
      lastModified: Date.now(),
    }
  );

  const formData = new FormData();
  formData.append('file', audioFile);

  let response: Response;

  try {
    response = await fetch(VOICE_CHAT_FUNCTION_URL, {
      method: 'POST',
      body: formData,
      // ‚ùó N√ÉO definir headers manualmente
    });
  } catch (err) {
    console.error('[VoiceChatService] Network error:', err);
    throw new Error('Falha de conex√£o com o backend');
  }

  if (!response.ok) {
    const errorText = await response.text();
    console.error('[VoiceChatService] Backend error:', errorText);
    throw new Error(`Erro na API (${response.status})`);
  }

  let data: any;

  try {
    data = await response.json();
  } catch {
    throw new Error('Resposta inv√°lida do backend (JSON)');
  }

  if (!data || typeof data.transcript !== 'string') {
    throw new Error('Transcri√ß√£o n√£o retornada pelo backend');
  }

  return {
    transcript: data.transcript,
    response: typeof data.response === 'string' ? data.response : '',
    success: true,
  };
}

/**
 * Apenas transcri√ß√£o (sem resposta da IA)
 */
export async function transcribeAudio(
  audioBlob: Blob
): Promise<string> {
  if (!(audioBlob instanceof Blob)) {
    throw new Error('Objeto de √°udio inv√°lido');
  }

  if (audioBlob.size === 0) {
    throw new Error('√Åudio vazio');
  }

  const audioFile = new File(
    [audioBlob],
    'audio.webm',
    {
      type: audioBlob.type || 'audio/webm',
      lastModified: Date.now(),
    }
  );

  const formData = new FormData();
  formData.append('file', audioFile);
  formData.append('transcriptOnly', 'true');

  const response = await fetch(VOICE_CHAT_FUNCTION_URL, {
    method: 'POST',
    body: formData,
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(
      `Erro na transcri√ß√£o (${response.status}): ${errorText}`
    );
  }

  const data = await response.json();

  if (!data || typeof data.transcript !== 'string') {
    throw new Error('Transcri√ß√£o vazia');
  }

  return data.transcript;
}
